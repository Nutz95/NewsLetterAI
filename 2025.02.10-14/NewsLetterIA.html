<style>
    body {
        font-family: Calibri, sans-serif;
        background-color: #f4f4f4;
        margin: 0;
        padding: 0;
    }
    .container {
        max-width: 1024px;
        margin: 20px auto;
        background: #ffffff;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    .header {
        text-align: center;
        padding-bottom: 20px;
        position: relative;
    }
    .header img {
        max-width: 200px;
        margin-bottom: 10px;
    }
    .header h1 {
        color: #333;
        margin: 0;
    }
    .period {
        text-align: right;
        font-size: 14px;
        color: #555;
        margin-top: 5px;
    }
    .toc {
        background: #007BFF;
        color: white;
        padding: 10px;
        border-radius: 5px;
    }
    .toc ul {
        list-style: none;
        padding: 0;
    }
    .toc li {
        margin: 5px 0;
    }
    .toc a {
        color: white;
        text-decoration: none;
    }
    .section {
        margin-top: 20px;
        padding: 15px;
        background: #f9f9f9;
        border-radius: 8px;
    }
    .section h2 {
        color: #007BFF;
    }
    .article {
        border-bottom: 1px solid #ddd;
        padding-bottom: 10px;
        margin-bottom: 10px;
    }
    .article:last-child {
        border-bottom: none;
    }
    .video {
        text-align: center;
        margin: 20px 0;
    }
    .video img {
        max-width: 100%;
        border-radius: 8px;
    }
    .button {
        display: block;
        width: 200px;
        margin: 20px auto;
        padding: 10px;
        background: #007BFF;
        color: white;
        text-align: center;
        text-decoration: none;
        border-radius: 5px;
    }
    .footer {
        text-align: center;
        margin-top: 20px;
        font-size: 14px;
        color: #777;
    }
	.nav-link {
		display: inline-block;
		margin-top: 10px;
	}
	.nav-link a {
		color: #007BFF;
		text-decoration: none;
		font-weight: bold;
	}
	.nav-link a:hover {
		text-decoration: underline;
	}
</style>

<div class="container">
    <div class="header">
        <img src="https://raw.githubusercontent.com/Nutz95/NewsLetterAI/refs/heads/main/Logo.png" alt="Logo Newsletter">
        <h1> La Miscellanews Letter IA – by Nico</h1>
        <div class="period">Période du 10 au 14 février 2025</div>
		<div class="nav-link">
			<a href="https://nutz95.github.io/NewsLetterAI/">Retour à l'index</a>
        </div>
    </div>

    <div class="toc">
        <h3>Sommaire</h3>
        <ul>
			<li><a href="#actu">Actu</a></li>
            <li><a href="#llm">LLM et génération de texte</a></li>
        </ul>
    </div>
    
	<div id="actu" class="section">
        <h2>Actu</h2>
        <div class="article">
            <h3>Annonces de la France concernant le développement de l'IA:</h3>
            <p>Quelques liens:</p>
            <ul>
                <li><a href="https://www.iliad.fr/fr/actualites/article/le-groupe-iliad-investit-3-milliards-d-euros-dans-l-ia">https://www.iliad.fr/fr/actualites/article/le-groupe-iliad-investit-3-milliards-d-euros-dans-l-ia</a></li>
                <li><a href="https://www.lemonde.fr/economie/article/2025/02/09/intelligence-artificielle-avec-l-annonce-de-109-milliards-d-euros-d-investissement-emmanuel-macron-entend-se-mesurer-aux-etats-unis_6539184_3234.html">https://www.lemonde.fr/economie/article/2025/02/09/intelligence-artificielle-avec-l-annonce-de-109-milliards-d-euros-d-investissement-emmanuel-macron-entend-se-mesurer-aux-etats-unis_6539184_3234.html</a></li>
                <li><a href="https://www.silicon.fr/Thematique/data-ia-1372/Breves/sommet-l-public-l-initiative-current-ai-467543.htm">https://www.silicon.fr/Thematique/data-ia-1372/Breves/sommet-l-public-l-initiative-current-ai-467543.htm</a></li>
                <li><a href="https://www.usine-digitale.fr/editorial/mistral-ai-va-ouvrir-son-premier-data-center-en-france.N2227191">https://www.usine-digitale.fr/editorial/mistral-ai-va-ouvrir-son-premier-data-center-en-france.N2227191</a></li>
            </ul>
            <p>Voici un résumé des annonces principales qui ont été faites lors du sommet sur l'IA qui s'est déroulé récemment en France:</p>
            <ul>
                <li><strong>Investissements massifs dans l'IA</strong>: Emmanuel Macron a annoncé que la France investirait 109 milliards d'euros dans l'intelligence artificielle, un montant comparable à l'investissement américain dans le projet "Stargate". Une part importante de ces fonds sera allouée à la construction de centres de données.</li>
                <li><strong>Construction de centres de données</strong>: Les Émirats arabes unis, par le biais du fonds d'investissement MGX, vont investir entre 30 et 50 milliards d'euros pour construire un centre de données géant d'un gigawatt en France. Ce centre fera partie du plus grand campus axé sur l'IA en Europe. Le fonds canadien Brookfield prévoit également d'investir 20 milliards d'euros en France d'ici 2030, dont 15 milliards seront consacrés à de nouveaux centres de données, notamment un centre de données géant à Cambrai.</li>
                <li><strong>Déclaration pour une IA ouverte, inclusive et éthique</strong>: 58 pays, dont la Chine, la France et l'Inde, ainsi que l'UE et la Commission de l'Union africaine, ont signé une déclaration commune en faveur d'une IA "ouverte", "inclusive" et "éthique". Les signataires souhaitent une coordination accrue de la gouvernance de l'IA et veulent éviter une "concentration du marché" afin de rendre cette technologie plus accessible.</li>
                <li><strong>Lancement de "Current AI"</strong>: Neuf pays, dont la France, ainsi que des associations et des entreprises, ont annoncé le lancement de "Current AI", un véhicule d'investissement pour une IA "d'intérêt général" doté d'un montant initial de 400 millions de dollars, avec l'objectif de lever 2,5 milliards de dollars sur cinq ans.</li>
                <li><strong>Opposition à la restriction de l'accès aux outils d'IA</strong>: La Chine s'est prononcée contre toute mesure visant à limiter l'accès aux outils d'intelligence artificielle et a plaidé pour une technologie d'IA open source et accessible à tous les pays.</li>
            </ul>
            <p>Suite aux annonces de Macron sur l'investissement de la France dans l'IA, plusieurs FAI se sont lancés à proposer gratuitement des services d'IA à leurs abonnés.</p>
        </div>
		<div class="article">
            <h3>Mistral Chat pro gratuit pendant 1 an avec Free Mobile.</h3>
            <p>Free a ouvert le bal en lançant son offre 1 an d'accès gratuit au chat de Mistral (version Pro). Le détail de l'offre sur le site officiel : <a href="https://portail.free.fr/mag-free/bons-plans/chat-pro-mistral-intelligence-artificielle-12-mois-gratuit-abonnes-free/">https://portail.free.fr/mag-free/bons-plans/chat-pro-mistral-intelligence-artificielle-12-mois-gratuit-abonnes-free/</a></p>
            <p>Pour ce prix là (donc 0€) vous avez un accès au chat en ligne ou via l'application sur téléphone. Le chat pro est similaire à ChatGPT, mais utilise les modèles internes de Mistral. Vous pourrez envoyer des images, générer des images. Le client web offre plus de possibilités que l'application mobile à ce que j'ai pu expérimenter. En terme de fonctionnalités cela reste moins intéressant que DeepSeek car ce dernier permet également de générer des vidéos et de faire de la recherche sur internet. Si vous voulez jouer avec l'API Mistral vous pourrez également le faire en souscrivant au service directement sur votre compte Mistral. L'accès à l'API est gratuit pour les développeurs mais reste limité en requêtes.</p>
        </div>
		<div class="article">
            <h3>Bouygues Telecom offre l'accès au moteur de recherche IA Perplexity à ses abonnés pendant 1 an.</h3>
            <p>Voilà l'article officiel: <a href="https://www.corporate.bouyguestelecom.fr/archives-communique-presse/partenaire-telecom-exclusif-de-perplexity-en-france-bouygues-telecom-est-le-seul-operateur-a-offrir-a-tous-ses-clients-un-acces-gratuit-au-moteur-de-recherche-ia-perplexity-pro/">https://www.corporate.bouyguestelecom.fr/archives-communique-presse/partenaire-telecom-exclusif-de-perplexity-en-france-bouygues-telecom-est-le-seul-operateur-a-offrir-a-tous-ses-clients-un-acces-gratuit-au-moteur-de-recherche-ia-perplexity-pro/</a></p>
            <p>Ce qui pour moi est plus intéressant que Mistral, car Perplexity a accès à internet, à des documents de recherches ou à du contenu de réseaux sociaux, et est spécialisé pour vous faire de très bons résumés d'articles en ligne.</p>
        </div>
    </div>
	
    <div id="llm" class="section">
        <h2>LLM et génération de texte</h2>
        <div class="article">
            <h2>Mises à jour Ollama 0.5.9 et supérieur.</h2>
            <p>Cette mise à jour apporte le support de nouveaux modèles avec raisonnement tels que:</p>
            <ul>
                <li><strong>DeepScaler</strong> (<a href="https://ollama.com/library/deepscaler">https://ollama.com/library/deepscaler</a>): "A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAI’s o1-preview with just 1.5B parameters on popular math evaluations."</li>
                <li><strong>OpenThinker</strong> (<a href="https://ollama.com/library/openthinker">https://ollama.com/library/openthinker</a>): "A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1."</li>
            </ul>
            <p>A titre personnel, j'ai pu essayer DeepScaler et j'ai été bluffé, le modèle ne fait que 1.5B donc il est relativement léger (3.6GB) et est doté de raisonnement. Du coup de part sa taille sa vitesse d'inférence est vraiment impressionnante, et ses capacités sont très bonnes pour ce type de modèles légers.</p>
        </div>
		<div class="article">
            <h2>Développement C#:</h2>
            <p>J'ai pu jouer un peu avec 3 Agentic framework, à savoir:</p>
            <ul>
                <li><strong>AutoGen</strong> (Git: <a href="https://github.com/microsoft/autogen">https://github.com/microsoft/autogen</a>, Doc .NET: <a href="https://microsoft.github.io/autogen-for-net/">https://microsoft.github.io/autogen-for-net/</a>)</li>
                <li><strong>LangChain</strong> (Git: <a href="https://github.com/tryAGI/LangChain">https://github.com/tryAGI/LangChain</a>)</li>
                <li><strong>Semantic Kernel</strong> (Git: <a href="https://github.com/microsoft/semantic-kernel">https://github.com/microsoft/semantic-kernel</a>, How to get starte: <a href="https://devblogs.microsoft.com/semantic-kernel/how-to-get-started-using-semantic-kernel-net/">https://devblogs.microsoft.com/semantic-kernel/how-to-get-started-using-semantic-kernel-net/</a>)</li>
            </ul>
            <h3>AutoGen (.NET)</h3>
            <p><strong>Concept clé:</strong> AutoGen est axé sur la création d'agents conversationnels multi-agents qui peuvent collaborer pour résoudre des tâches complexes. Il permet de définir des rôles et des responsabilités pour chaque agent et de gérer les interactions entre eux.</p>
            <h4>Avantages:</h4>
            <ul>
                <li>Idéal pour les applications nécessitant une collaboration entre plusieurs agents IA (par exemple, un agent qui écrit du code et un autre qui le teste).</li>
                <li>Offre un haut degré de contrôle sur le comportement des agents et leurs interactions.</li>
                <li>Prise en charge native de .NET, ce qui simplifie l'intégration dans les projets existants.</li>
            </ul>
            <h4>Inconvénients:</h4>
            <ul>
                <li>Peut être plus complexe à mettre en œuvre que LangChain ou Semantic Kernel pour des tâches simples.</li>
                <li>La documentation et les exemples en français peuvent être limités.</li>
            </ul>
            <h4>Cas d'utilisation:</h4>
            <ul>
                <li>Développement d'assistants virtuels complexes.</li>
                <li>Automatisation de processus métier impliquant plusieurs étapes et acteurs.</li>
                <li>Création de jeux vidéo avec des personnages IA collaboratifs.</li>
            </ul>
            <h3>LangChain</h3>
            <p><strong>Concept clé:</strong> LangChain est une boîte à outils complète pour le développement d'applications basées sur les LLM (Large Language Models). Il offre des modules pour la gestion des prompts, l'intégration de bases de données, la création de chaînes d'actions et bien plus encore.</p>
            <h4>Avantages:</h4>
            <ul>
                <li>Très flexible et adaptable à une grande variété de cas d'utilisation.</li>
                <li>Dispose d'une vaste communauté et d'une documentation complète (principalement en anglais).</li>
                <li>Permet de créer des applications IA complexes en combinant différents modules.</li>
            </ul>
            <h4>Inconvénients:</h4>
            <ul>
                <li>La courbe d'apprentissage peut être abrupte en raison de sa complexité.</li>
                <li>La version .NET peut être moins mature que les versions Python ou JavaScript.</li>
            </ul>
            <h4>Cas d'utilisation:</h4>
            <ul>
                <li>Création de chatbots et d'assistants virtuels.</li>
                <li>Génération de contenu (textes, images, code).</li>
                <li>Analyse de données et extraction d'informations.</li>
            </ul>
            <h3>Semantic Kernel</h3>
            <p><strong>Concept clé:</strong> Semantic Kernel se concentre sur l'intégration de l'IA dans les applications existantes en utilisant des "skills" (compétences). Un skill est une fonction que le modèle de langage peut exécuter, permettant d'ajouter des fonctionnalités d'IA à une application sans avoir à réécrire le code existant.</p>
            <h4>Avantages:</h4>
            <ul>
                <li>Facile à intégrer dans les applications .NET existantes.</li>
                <li>Permet d'ajouter rapidement des fonctionnalités d'IA sans nécessiter une expertise approfondie en machine learning.</li>
                <li>Concept de "skills" réutilisables et partageables.</li>
            </ul>
            <h4>Inconvénients:</h4>
            <ul>
                <li>Moins flexible que LangChain pour les applications IA complexes nécessitant un contrôle fin sur le modèle de langage.</li>
                <li>Peut être limité pour les cas d'utilisation qui ne peuvent pas être facilement décomposés en "skills".</li>
            </ul>
            <h4>Cas d'utilisation:</h4>
            <ul>
                <li>Ajout de fonctionnalités d'IA à des applications web ou de bureau existantes.</li>
                <li>Automatisation de tâches répétitives.</li>
                <li>Création d'interfaces utilisateur plus intelligentes et adaptatives.</li>
            </ul>
            <h3>Tableau comparatif résumé:</h3>
            <img src="https://raw.githubusercontent.com/Nutz95/NewsLetterAI/refs/heads/main/2025.02.10-14/tableau.png" alt="Tableau comparatif résumé">
            <h3>Retour personnel</h3>
            <h4>Autogen:</h4>
            <p>De ce que j'ai pu tester, Autogen semble avoir bien évolué (gros changement entre la version 0.2.0 et 0.4.6) et certains aspects du framework semblent encore incomplets ou hasardeux, surtout lorsqu'on joue avec l'appel de fonction. Le code d'exemple est parfois insuffisant et il faut parfois aller chercher dans le code source des réponses à certains comportements.</p>
            <h4>LangChain:</h4>
            <p>On sent bien que le framework a du potentiel mais j'ai eu beaucoup d'exceptions lors de l'utilisation de fonctions, des fois la désérialisation ou la détection des demandes d'utilisation d'outils par les LLM semble poser beaucoup de problèmes et des exceptions sont levées à l'intérieur du framework. On sent bien que ce framework est mature au niveau du support du python, mais quand au support du C#, malgré sa flexibilité et sa philosophie, c'est pratiquement inutilisable, ou alors il faut vraiment passer du temps à fine-tuner tous les prompts pour contraindre les modèles à générer le type de réponse que sait interpréter LangChain.</p>
            <h4>Semantic Kernel:</h4>
            <p>C'est pour moi l'approche la plus viable de part les nombreux cas abordés dans le repo git qui montre facilement tous les cas d'usage. On sent que le framework est bien plus mature que les autres, l'utilisation d'outils ou de fonctions par les LLM est bien mieux supporté, et de nombreux exemples sont disponibles avec quasiment tous les provider possible (mistral, OpenAI, Azure etc....) Beaucoup d'exemples sont aussi disponibles sur des applications comme la navigation web, l'appel de fonction, l'utilisation de groupe de chat, , le RAG, etc.... Le framework est relativement facile à utiliser et supporte nativement l'injection de dépendance, possède un pipeline, une gestion de filtres, etc.... On sent que ce framework est fait pour s'intégrer dans des applications et environnements microsoft.</p>
        </div>
    </div>
    <div class="footer">
        <p>© 2025 - Cérébris | Tous droits réservés</p>
		<div class="nav-link">
			<a href="https://nutz95.github.io/NewsLetterAI/">Retour à l'index</a>
        </div>
    </div>
</div>
